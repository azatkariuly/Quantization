{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple model architecture for solving MNIST, that uses 2 conv and 2 fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, mnist=True):\n",
    "      \n",
    "        super(Net, self).__init__()\n",
    "          \n",
    "        #conv1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1)\n",
    "        \n",
    "        #conv2\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, stride=1)\n",
    "        \n",
    "        #fully connected layer 1\n",
    "        self.fc1 = nn.Linear(in_features=4*4*50, out_features=500)\n",
    "        \n",
    "        #fully connected layer 2\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=10)\n",
    "\n",
    "    #forward function  \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)   \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def testQuant(model, test_loader, quant=False, stats=None):\n",
    "    device = 'cpu'\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if quant:\n",
    "                output = quantForward(model, data, stats)\n",
    "            else:\n",
    "                output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    " \n",
    "    batch_size = 64\n",
    "    test_batch_size = 64\n",
    "    epochs = 3\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 500\n",
    "    save_model = False\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "  \n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        testQuant(model, test_loader)\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/ILSVRC2012_devkit_t12.tar.gz\n",
      "Extracting ./data/ILSVRC2012_devkit_t12.tar.gz to /var/folders/th/1db1p8gj5jx_vgvgmsfdx57h0000gn/T/tmpulg8rl6x\n",
      "Downloading http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar to ./data/ILSVRC2012_img_val.tar\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-adf5083b3180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCenterCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])),\n\u001b[0m\u001b[1;32m      7\u001b[0m     batch_size=test_batch_size, shuffle=True, **kwargs)\n",
      "\u001b[0;32m~/.conda/envs/test/lib/python3.7/site-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, download, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mwnid_to_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_meta_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/test/lib/python3.7/site-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             download_and_extract_archive(archive_dict['url'], self.root,\n\u001b[1;32m     85\u001b[0m                                          \u001b[0mextract_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                                          md5=archive_dict['md5'])\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/test/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/test/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 )\n\u001b[1;32m     95\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/test/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5)\u001b[0m\n\u001b[1;32m     82\u001b[0m             urllib.request.urlretrieve(\n\u001b[1;32m     83\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_bar_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             )\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/test/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/test/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/test/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/test/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/test/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/test/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/test/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300039\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.337065\n",
      "\n",
      "Test set: Average loss: 0.1017, Accuracy: 9661/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.145472\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.034624\n",
      "\n",
      "Test set: Average loss: 0.0610, Accuracy: 9826/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.053590\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.029762\n",
      "\n",
      "Test set: Average loss: 0.0550, Accuracy: 9815/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 9.1196e-02, -1.1278e-01, -1.0681e-01, -3.7622e-03, -2.4457e-01],\n",
       "          [ 1.6207e-01,  2.9669e-02,  1.3495e-01,  4.6878e-02, -9.9357e-03],\n",
       "          [ 1.0880e-01,  1.1285e-01,  1.8251e-01,  2.5795e-02,  5.4897e-02],\n",
       "          [-3.3242e-02,  5.4917e-02,  4.2395e-02,  2.3614e-01,  1.4821e-01],\n",
       "          [-1.3611e-01, -1.7517e-01, -1.0584e-01, -1.2284e-01, -2.2899e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.0385e-02,  2.5570e-01,  1.9098e-01, -2.3319e-01,  4.3958e-02],\n",
       "          [ 1.3056e-01,  3.2718e-01,  1.7801e-01, -2.5750e-01, -2.8356e-01],\n",
       "          [ 8.2280e-03,  3.1927e-01, -1.4386e-02, -2.8260e-05, -1.8262e-01],\n",
       "          [ 2.8211e-01,  1.7638e-02,  1.5929e-01, -4.8542e-02, -1.4374e-01],\n",
       "          [ 1.8625e-01, -1.9564e-02,  8.1077e-02, -6.1486e-02, -1.8115e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.3365e-01, -1.2033e-01,  1.2521e-01,  3.4815e-02,  3.0283e-01],\n",
       "          [ 1.2494e-01,  7.7094e-03, -3.3054e-02,  2.7073e-01,  1.6790e-01],\n",
       "          [-1.2619e-01,  1.8656e-01,  2.3734e-01,  2.9217e-01, -7.7384e-02],\n",
       "          [ 1.1767e-02,  6.8039e-02,  9.4234e-02, -1.2398e-01, -1.6446e-01],\n",
       "          [ 1.6008e-01, -6.9234e-03,  1.0370e-01, -1.1949e-02,  2.4792e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.1472e-02,  5.4237e-02,  9.0657e-02, -1.7170e-01,  1.4890e-01],\n",
       "          [-1.5442e-01, -1.7129e-01,  6.1019e-03, -1.2840e-02,  1.7388e-01],\n",
       "          [-1.2721e-01, -1.8493e-01,  1.5311e-01, -4.0727e-03,  1.5331e-01],\n",
       "          [ 5.3319e-02, -1.4539e-01,  6.7480e-02,  7.6181e-02, -1.0666e-01],\n",
       "          [-9.5100e-02,  8.0701e-02,  6.7080e-02, -5.3390e-02, -3.6298e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.4736e-01,  5.4930e-02,  1.9436e-01,  9.5359e-02, -1.8944e-01],\n",
       "          [-9.2639e-02,  3.6351e-01,  1.6851e-01,  1.6867e-01, -8.4780e-03],\n",
       "          [ 1.7924e-01,  4.0013e-01,  3.8121e-01, -1.0700e-01, -1.5914e-02],\n",
       "          [ 2.4311e-01,  3.4186e-01,  2.7459e-01, -1.1512e-01, -1.6733e-01],\n",
       "          [-8.3433e-02,  1.2917e-01,  3.0132e-01, -8.6162e-02,  1.1430e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.4234e-01, -2.2665e-01, -3.5999e-02,  2.1093e-01,  2.9056e-01],\n",
       "          [-1.0347e-01,  1.0637e-01,  3.0875e-01,  3.0912e-01,  2.2907e-01],\n",
       "          [ 2.3139e-01,  2.3613e-01,  1.8119e-01, -7.9779e-03, -1.0749e-01],\n",
       "          [-2.2972e-02,  2.3089e-02, -7.6214e-02,  1.3946e-01,  9.1069e-02],\n",
       "          [-3.0396e-02,  6.8471e-02,  6.1260e-02,  1.4017e-01,  1.4089e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.6417e-02,  1.6380e-01, -5.3934e-02, -2.5019e-02, -1.9455e-01],\n",
       "          [-1.4637e-01, -1.4944e-01, -1.2339e-01,  1.1354e-01, -7.5405e-02],\n",
       "          [-1.6450e-01,  5.4081e-02,  3.5432e-02,  1.0289e-01, -1.1339e-01],\n",
       "          [ 4.6971e-02, -7.2717e-02, -5.1152e-02, -1.7196e-01, -8.4510e-02],\n",
       "          [-2.7336e-02,  1.2459e-01,  7.8598e-02,  9.8846e-02,  2.6682e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5720e-01,  1.8698e-01,  1.4791e-02, -1.5113e-01,  1.5119e-01],\n",
       "          [ 1.3017e-02, -1.4379e-04, -1.9915e-01, -6.8621e-02, -1.4077e-01],\n",
       "          [ 2.2148e-01, -1.8480e-01, -1.9100e-01, -2.9159e-02, -1.0258e-01],\n",
       "          [ 1.0165e-01, -7.2032e-02, -9.6590e-02,  2.7384e-02,  1.7590e-01],\n",
       "          [-1.0536e-01,  1.3971e-01,  1.8478e-01,  2.4309e-01, -1.1603e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.3072e-02, -1.7451e-01,  1.6560e-01, -5.3635e-02,  1.2435e-01],\n",
       "          [ 2.4141e-02, -5.2425e-04,  6.8224e-02,  1.7801e-01,  2.2320e-01],\n",
       "          [ 8.4451e-02,  1.1474e-01, -9.2426e-02,  2.8169e-01,  3.3894e-01],\n",
       "          [ 1.9225e-01,  1.5512e-01, -1.5631e-01, -8.0585e-02,  2.5661e-01],\n",
       "          [-2.2423e-01,  8.8328e-02, -2.5005e-01, -2.2153e-01,  1.0313e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.2316e-01, -1.5851e-03,  2.3007e-01,  2.4924e-01,  2.6361e-01],\n",
       "          [-2.8633e-02, -1.4250e-01,  2.5635e-01,  3.1817e-02, -1.7841e-02],\n",
       "          [ 2.4969e-02, -1.7959e-01,  1.2499e-01,  1.6469e-01, -1.1613e-01],\n",
       "          [-2.2214e-01, -8.9883e-02,  4.7630e-02,  1.6930e-02, -6.2575e-02],\n",
       "          [-5.0903e-02, -2.5006e-01, -1.7190e-01, -1.1605e-01,  1.9973e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.3772e-01, -3.2774e-03,  5.9817e-02,  1.2059e-01,  2.3229e-02],\n",
       "          [-1.3148e-02,  2.5233e-01,  2.5627e-01,  6.5825e-02, -4.9351e-03],\n",
       "          [ 2.6390e-01,  3.1058e-01, -4.5436e-04,  2.7907e-01,  7.6453e-02],\n",
       "          [-1.1503e-01,  1.6437e-01, -1.0633e-01,  2.2250e-01, -1.3466e-01],\n",
       "          [ 3.9317e-02,  7.9006e-02,  6.8710e-02,  1.8527e-01, -9.6778e-02]]],\n",
       "\n",
       "\n",
       "        [[[-8.6309e-02, -1.6455e-01,  1.5418e-02, -7.6121e-02,  1.6691e-02],\n",
       "          [-4.3228e-02,  7.5969e-02,  2.0610e-01,  8.7025e-02, -5.6828e-02],\n",
       "          [-1.0620e-01, -1.6865e-01,  2.0443e-01, -8.3825e-04,  6.3026e-02],\n",
       "          [ 2.1292e-03, -1.2232e-01,  1.4561e-01,  1.5037e-01,  3.4108e-02],\n",
       "          [-1.1701e-01, -6.9500e-02,  3.9191e-02, -8.6914e-02, -1.0486e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.0284e-02, -7.2029e-02,  5.5853e-02,  2.6189e-02,  9.6581e-02],\n",
       "          [-1.1376e-01, -2.2908e-01,  1.3390e-01,  9.0457e-02,  2.9621e-01],\n",
       "          [-8.0768e-02, -9.9860e-02, -2.1113e-01,  6.2073e-03,  2.5956e-01],\n",
       "          [-2.4428e-01, -1.2096e-01,  9.9006e-02,  1.7787e-01,  1.7272e-01],\n",
       "          [-8.1886e-02, -3.6900e-02, -1.5343e-02,  1.0213e-02,  1.7980e-01]]],\n",
       "\n",
       "\n",
       "        [[[-6.7179e-02, -1.1168e-01,  4.8726e-02, -1.3859e-01, -4.2335e-02],\n",
       "          [ 9.2301e-02,  6.7860e-02,  1.6671e-01, -1.3956e-01, -5.7416e-03],\n",
       "          [-8.0700e-02, -1.2683e-01, -1.2821e-01,  2.6123e-02, -4.3022e-03],\n",
       "          [-1.2036e-01, -1.5737e-01, -1.8608e-01,  1.6138e-01, -6.7273e-02],\n",
       "          [-6.8830e-02, -9.3851e-02, -1.2468e-01, -2.1234e-01, -1.4620e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.9190e-01,  2.6057e-01,  1.4607e-01,  7.1448e-02,  2.1813e-01],\n",
       "          [ 2.9553e-01,  4.1556e-01,  2.8582e-01,  2.4598e-01,  9.5129e-02],\n",
       "          [-1.8079e-01, -1.9379e-01,  1.2992e-01, -1.9646e-02,  1.2912e-01],\n",
       "          [-1.4211e-01, -3.0718e-01, -2.3437e-01, -3.4898e-02, -4.7059e-02],\n",
       "          [-3.1416e-01, -4.8743e-02, -1.1631e-01, -1.4669e-01,  5.7772e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.6325e-02, -8.7864e-02,  1.7668e-01,  7.0215e-02, -5.2741e-02],\n",
       "          [-1.7868e-02, -1.4870e-01,  1.8245e-01, -8.8180e-02, -2.2675e-01],\n",
       "          [ 2.2228e-01,  1.9434e-01,  1.6137e-01, -2.4554e-03, -8.6537e-02],\n",
       "          [ 1.3899e-01,  3.2401e-01,  2.1313e-01,  6.1587e-02,  2.9721e-01],\n",
       "          [ 2.7230e-02,  2.3374e-01,  1.7249e-01,  3.1209e-01,  2.2934e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.2490e-01,  1.0991e-01, -1.8146e-02, -1.6276e-01, -4.0558e-02],\n",
       "          [-2.0018e-01, -1.3162e-01, -1.5861e-01,  1.3983e-01, -3.5067e-02],\n",
       "          [-2.8474e-02,  9.9928e-02,  8.8377e-02, -1.1083e-01,  9.7197e-02],\n",
       "          [ 1.1010e-01, -1.2730e-01,  2.1946e-01, -7.4555e-02, -4.4862e-02],\n",
       "          [-1.4416e-01,  2.2841e-01,  1.0170e-01,  2.3104e-01,  5.6556e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2681e-01, -7.0040e-02, -1.7781e-01,  2.0307e-02, -1.2901e-02],\n",
       "          [-1.4090e-02, -8.9203e-02,  2.8477e-02,  1.0681e-01,  1.2882e-01],\n",
       "          [-1.4706e-01,  1.4978e-01,  1.0732e-01,  2.2790e-01,  2.1513e-01],\n",
       "          [-1.0874e-01,  2.6868e-01, -1.3129e-01,  1.4914e-01,  3.0931e-02],\n",
       "          [ 1.5670e-01, -7.0662e-02,  1.2001e-01, -1.3435e-01, -2.0724e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1351e-01,  2.0546e-01,  3.2768e-01,  7.7365e-02,  2.3631e-01],\n",
       "          [ 1.3053e-01, -5.9642e-02, -8.7705e-02,  1.6351e-01, -8.7751e-02],\n",
       "          [ 2.9833e-02, -1.8749e-01,  1.3643e-01,  6.8421e-02, -1.1755e-02],\n",
       "          [ 1.6193e-02, -1.8102e-01, -8.1030e-02,  1.7345e-02, -7.7488e-02],\n",
       "          [-1.0718e-01, -1.1767e-01,  1.7392e-01,  2.1276e-01,  2.4588e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3460e-01, -2.0420e-01,  6.0251e-02,  7.8732e-02, -1.5684e-01],\n",
       "          [ 4.6517e-02, -1.2242e-01,  5.5069e-02,  1.4361e-01,  2.3389e-01],\n",
       "          [-1.2496e-01, -1.3479e-01,  2.6083e-01,  1.7851e-01,  1.6401e-01],\n",
       "          [ 7.7613e-02, -9.6757e-03,  1.7382e-01, -1.6573e-01,  3.1065e-02],\n",
       "          [ 1.1303e-01,  1.6258e-01, -1.1214e-01, -1.7416e-01,  4.8221e-02]]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Whitepaper: Uniform Affine Quantizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula: <br>\n",
    "\n",
    "<center><i>x_int = round(x/scale) + zero_point</i></center>\n",
    "<center><i>x_Q = clamp(0, qmax-1, x_int)</i></center>\n",
    "\n",
    "De-quantization, <center><i>x = x_Q * scale<i></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "QTensor = namedtuple('QTensor', ['tensor', 'scale', 'zero_point'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcScaleZeroPoint(min_val, max_val,num_bits=8):\n",
    "    # Calc Scale and zero point of next \n",
    "    qmin = 0.\n",
    "    qmax = 2.**num_bits - 1.\n",
    "\n",
    "    scale = (max_val - min_val) / (qmax - qmin)\n",
    "\n",
    "    initial_zero_point = qmin - min_val / scale\n",
    "\n",
    "    zero_point = 0\n",
    "    if initial_zero_point < qmin:\n",
    "        zero_point = qmin\n",
    "    elif initial_zero_point > qmax:\n",
    "        zero_point = qmax\n",
    "    else:\n",
    "        zero_point = initial_zero_point\n",
    "\n",
    "    zero_point = int(zero_point)\n",
    "\n",
    "    return scale, zero_point\n",
    "\n",
    "def quantize_tensor(x, num_bits=8, min_val=None, max_val=None):\n",
    "    \n",
    "    if not min_val and not max_val: \n",
    "        min_val, max_val = x.min(), x.max()\n",
    "\n",
    "    qmin = 0.\n",
    "    qmax = 2.**num_bits - 1.\n",
    "\n",
    "    scale, zero_point = calcScaleZeroPoint(min_val, max_val, num_bits)\n",
    "    q_x = zero_point + x / scale\n",
    "    q_x.clamp_(qmin, qmax).round_()\n",
    "    q_x = q_x.round().byte()\n",
    "    \n",
    "    return QTensor(tensor=q_x, scale=scale, zero_point=zero_point)\n",
    "\n",
    "def dequantize_tensor(q_x):\n",
    "    return q_x.scale * (q_x.tensor.float() - q_x.zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizeLayer(x, layer, stat, scale_x, zp_x):\n",
    "    # for both conv and linear layers\n",
    "\n",
    "    # cache old values\n",
    "    W = layer.weight.data\n",
    "    B = layer.bias.data\n",
    "\n",
    "    # quantise weights, activations are already quantised\n",
    "    w = quantize_tensor(layer.weight.data) \n",
    "    b = quantize_tensor(layer.bias.data)\n",
    "\n",
    "    layer.weight.data = w.tensor.float()\n",
    "    layer.bias.data = b.tensor.float()\n",
    "\n",
    "    # This is Quantisation Artihmetic\n",
    "    scale_w = w.scale\n",
    "    zp_w = w.zero_point\n",
    "    scale_b = b.scale\n",
    "    zp_b = b.zero_point\n",
    "  \n",
    "    scale_next, zero_point_next = calcScaleZeroPoint(min_val=stat['min'], max_val=stat['max'])\n",
    "\n",
    "    # Preparing input by shifting\n",
    "    X = scale_x*(x.float() - zp_x)\n",
    "    layer.weight.data = scale_w*(layer.weight.data - zp_w)\n",
    "    #layer.weight.data = scale_w*(layer.weight.data - zp_w)\n",
    "    layer.bias.data = scale_b*(layer.bias.data - zp_b)\n",
    "\n",
    "    # All int computation\n",
    "    x = (layer(X)/ scale_next).round() + zero_point_next \n",
    "\n",
    "    # Perform relu too\n",
    "    x = F.relu(x)\n",
    "\n",
    "    # Reset weights for next forward pass\n",
    "    layer.weight.data = W\n",
    "    layer.bias.data = B\n",
    "  \n",
    "    return x, scale_next, zero_point_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Max and Min Stats for Quantising Activations of Network.\n",
    "This is done by running the network with around 1000 examples and getting the average min and max activation values before and after each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Min and max of x tensor, and stores it\n",
    "def updateStats(x, stats, key):\n",
    "    max_val, _ = torch.max(x, dim=1)\n",
    "    min_val, _ = torch.min(x, dim=1)\n",
    "  \n",
    "  \n",
    "    if key not in stats:\n",
    "        stats[key] = {\"max\": int(max_val.sum()), \"min\": int(min_val.sum())}\n",
    "    else:\n",
    "        if stats[key]['max'] < int(max_val.sum().item()):\n",
    "            stats[key]['max'] = int(max_val.sum().item())\n",
    "        if stats[key]['min'] > min_val.sum().item():\n",
    "            stats[key]['min'] = int(min_val.sum().item())\n",
    "  \n",
    "    return stats\n",
    "\n",
    "# Reworked Forward Pass to access activation Stats through updateStats function\n",
    "def gatherActivationStats(model, x, stats):\n",
    "\n",
    "    stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv1') \n",
    "    \n",
    "    x = F.relu(model.conv1(x))\n",
    "\n",
    "    x = F.max_pool2d(x, 2, 2)\n",
    "  \n",
    "    stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv2')\n",
    "  \n",
    "    x = F.relu(model.conv2(x))\n",
    "\n",
    "    x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "    x = x.view(-1, 4*4*50)\n",
    "  \n",
    "    stats = updateStats(x, stats, 'fc1')\n",
    "\n",
    "    x = F.relu(model.fc1(x))\n",
    "  \n",
    "    stats = updateStats(x, stats, 'fc2')\n",
    "\n",
    "    x = model.fc2(x)\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Entry function to get stats of all functions.\n",
    "def gatherStats(model, test_loader):\n",
    "    device = 'cpu'\n",
    "    \n",
    "    model.eval()\n",
    "    stats = {}\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            stats = gatherActivationStats(model, data, stats)\n",
    "    \n",
    "    final_stats = {}\n",
    "    for key, value in stats.items():\n",
    "          final_stats[key] = { \"max\" : value[\"max\"], \"min\" : value[\"min\"]}\n",
    "    return final_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantForward(model, x, stats):\n",
    "  \n",
    "    # Quantise before inputting into incoming layers\n",
    "    x = quantize_tensor(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'])\n",
    "\n",
    "    x, scale_next, zero_point_next = quantizeLayer(x.tensor, model.conv1, stats['conv2'], x.scale, x.zero_point)\n",
    "\n",
    "    x = F.max_pool2d(x, 2, 2)\n",
    "  \n",
    "    x, scale_next, zero_point_next = quantizeLayer(x, model.conv2, stats['fc1'], scale_next, zero_point_next)\n",
    "\n",
    "    x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "    x = x.view(-1, 4*4*50)\n",
    "\n",
    "    x, scale_next, zero_point_next = quantizeLayer(x, model.fc1, stats['fc2'], scale_next, zero_point_next)\n",
    "  \n",
    "    # Back to dequant for final layer\n",
    "    x = dequantize_tensor(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n",
    "   \n",
    "    x = model.fc2(x)\n",
    "\n",
    "    return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Quantizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "q_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])), \n",
    "    batch_size=64, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0550, Accuracy: 9815/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testQuant(q_model, test_loader, quant=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats of Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2590, Accuracy: 9771/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testQuant(q_model, test_loader, quant=True, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv1': {'max': 180, 'min': -27}, 'conv2': {'max': 531, 'min': 0}, 'fc1': {'max': 866, 'min': 0}, 'fc2': {'max': 465, 'min': 0}}\n"
     ]
    }
   ],
   "source": [
    "stats = gatherStats(q_model, test_loader)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0617, Accuracy: 9800/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testQuant(q_model, test_loader, quant=True, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
