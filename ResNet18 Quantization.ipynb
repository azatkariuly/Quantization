{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/azatkariuly/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "#trained weights\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open(filename)\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(258)\n"
     ]
    }
   ],
   "source": [
    "#target\n",
    "print(output.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform Affine Quantizer\n",
    "Formula: <br>\n",
    "\n",
    "<center><i>x_int = round(x/scale) + zero_point</i></center>\n",
    "<center><i>x_Q = clamp(0, qmax-1, x_int)</i></center>\n",
    "\n",
    "De-quantization, <center><i>x = (x_Q - zero_point) * scale<i></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "QTensor = namedtuple('QTensor', ['tensor', 'scale', 'zero_point'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcScaleZeroPoint(min_val, max_val,num_bits=8):\n",
    "    # Calc Scale and zero point of next \n",
    "    qmin = 0.\n",
    "    qmax = 2.**num_bits - 1.\n",
    "\n",
    "    scale = (max_val - min_val) / (qmax - qmin)\n",
    "\n",
    "    initial_zero_point = qmin - min_val / scale\n",
    "\n",
    "    zero_point = 0\n",
    "    if initial_zero_point < qmin:\n",
    "        zero_point = qmin\n",
    "    elif initial_zero_point > qmax:\n",
    "        zero_point = qmax\n",
    "    else:\n",
    "        zero_point = initial_zero_point\n",
    "\n",
    "    zero_point = int(zero_point)\n",
    "\n",
    "    return scale, zero_point\n",
    "\n",
    "def quantize_tensor(x, num_bits=8, min_val=None, max_val=None):\n",
    "    \n",
    "    if not min_val and not max_val: \n",
    "        min_val, max_val = x.min(), x.max()\n",
    "\n",
    "    qmin = 0.\n",
    "    qmax = 2.**num_bits - 1.\n",
    "\n",
    "    scale, zero_point = calcScaleZeroPoint(min_val, max_val, num_bits)\n",
    "    q_x = zero_point + x / scale\n",
    "    q_x.clamp_(qmin, qmax).round_()\n",
    "    \n",
    "    return QTensor(tensor=q_x, scale=scale, zero_point=zero_point)\n",
    "\n",
    "def dequantize_tensor(q_x):\n",
    "    return q_x.scale * (q_x.tensor.float() - q_x.zero_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass to support Quantization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizeLayer(x, layer, stat, scale_x, zp_x, num_bits=8):\n",
    "    # cache old values\n",
    "    W = layer.weight.data\n",
    "\n",
    "    # quantise weights\n",
    "    w = quantize_tensor(layer.weight.data) \n",
    "\n",
    "    layer.weight.data = w.tensor\n",
    "\n",
    "    # This is Quantisation Artihmetic\n",
    "    scale_w = w.scale\n",
    "    zp_w = w.zero_point\n",
    "  \n",
    "    scale_next, zero_point_next = calcScaleZeroPoint(min_val=stat['min'], max_val=stat['max'])\n",
    "\n",
    "    # Preparing input by shifting\n",
    "    X = scale_x*(x.float() - zp_x)\n",
    "    layer.weight.data = scale_w*(layer.weight.data.float() - zp_w)\n",
    "\n",
    "    # All int computation\n",
    "    x = layer(X)/scale_next + zero_point_next\n",
    "    \n",
    "    #make sure that x stays in desired range\n",
    "    x.clamp_(0., 2.**num_bits - 1.).round_()\n",
    "\n",
    "    # Reset weights for next forward pass\n",
    "    layer.weight.data = W\n",
    "  \n",
    "    return x, scale_next, zero_point_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def quantizeBlock(x, block, stats, stats_next, scale_next, zero_point_next, num_bits=8):\n",
    "    \n",
    "    #copy x\n",
    "    identity = x\n",
    "    scale_next1 = scale_next\n",
    "    zero_point_next1 = zero_point_next\n",
    "    \n",
    "    #conv1\n",
    "    x, scale_next, zero_point_next = quantizeLayer(x, block.conv1, stats['bn1'], scale_next, zero_point_next)\n",
    "    \n",
    "    #bn1\n",
    "    x, scale_next, zero_point_next = quantizeLayer(x, block.bn1, stats['conv2'], scale_next, zero_point_next)\n",
    "    \n",
    "    #relu\n",
    "    x = F.relu(x)\n",
    "    \n",
    "    #conv2\n",
    "    x, scale_next, zero_point_next = quantizeLayer(x, block.conv2, stats['bn2'], scale_next, zero_point_next)    \n",
    "    \n",
    "    #bn2\n",
    "    x, scale_next, zero_point_next = quantizeLayer(x, block.bn2, stats_next, scale_next, zero_point_next)\n",
    "\n",
    "    #if has downsample, updates the copy of x\n",
    "    if block.downsample is not None:\n",
    "        #0\n",
    "        identity, scale_next1, zero_point_next1 = quantizeLayer(identity, block.downsample[0], \n",
    "                                                              stats['downsample']['0'],\n",
    "                                                                scale_next1, zero_point_next1)\n",
    "        #1\n",
    "        identity, scale_next1, zero_point_next1 = quantizeLayer(identity, block.downsample[1], \n",
    "                                                                stats['downsample']['1'], \n",
    "                                                                scale_next1, zero_point_next1)\n",
    "        \n",
    "    \n",
    "    #sums new value and copy value of x\n",
    "    scale_z, zero_point_z = calcScaleZeroPoint(min_val=stats_next['min'], max_val=stats_next['max'])\n",
    "    x = ((x-zero_point_next)*scale_next + (identity-zero_point_next1)*scale_next1)/scale_z + zero_point_z\n",
    "        \n",
    "    #make sure that x stays in desired range\n",
    "    x.clamp_(0., 2.**num_bits - 1.).round_()\n",
    "    \n",
    "    #relu\n",
    "    x = F.relu(x)\n",
    "    \n",
    "    #return\n",
    "    return x, scale_z, zero_point_z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantForward(model, x, stats):\n",
    "    #quantize input before inputing to layer\n",
    "    x = quantize_tensor(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'])\n",
    "    #print('input: ', x)\n",
    "    \n",
    "    #conv1\n",
    "    x, scale_next, zero_point_next = quantizeLayer(x.tensor, model.conv1, stats['bn1'], x.scale, x.zero_point)\n",
    "    #print('conv1: ', x)   \n",
    "    \n",
    "    #bn1\n",
    "    x, scale_next, zero_point_next = quantizeLayer(x, model.bn1, stats['layer1_0']['conv1'], scale_next, zero_point_next)\n",
    "    #print('bn1: ', x)\n",
    "    \n",
    "    #relu\n",
    "    x = model.relu(x)\n",
    "    #print('relu: ', x)\n",
    "    \n",
    "    #maxpool\n",
    "    x = model.maxpool(x)\n",
    "    #print('maxpool: ', x)\n",
    "    \n",
    "    #layer1\n",
    "    x, scale_next, zero_point_next = quantizeBlock(x, model.layer1[0], stats['layer1_0'], \n",
    "                                                   stats['layer1_1']['conv1'], scale_next, zero_point_next)\n",
    "    x, scale_next, zero_point_next = quantizeBlock(x, model.layer1[1], stats['layer1_1'], \n",
    "                                                   stats['layer2_0']['conv1'], scale_next, zero_point_next)\n",
    "    #print('layer1: ', x)\n",
    "    \n",
    "    #layer2\n",
    "    x, scale_next, zero_point_next = quantizeBlock(x, model.layer2[0], stats['layer2_0'], \n",
    "                                                   stats['layer2_1']['conv1'], scale_next, zero_point_next)\n",
    "    x, scale_next, zero_point_next = quantizeBlock(x, model.layer2[1], stats['layer2_1'], \n",
    "                                                   stats['layer3_0']['conv1'], scale_next, zero_point_next)\n",
    "    #print('layer2: ', x)\n",
    "    \n",
    "    #layer3\n",
    "    x, scale_next, zero_point_next = quantizeBlock(x, model.layer3[0], stats['layer3_0'], \n",
    "                                                   stats['layer3_1']['conv1'], scale_next, zero_point_next)\n",
    "    x, scale_next, zero_point_next = quantizeBlock(x, model.layer3[1], stats['layer3_1'], \n",
    "                                                   stats['layer4_0']['conv1'], scale_next, zero_point_next)\n",
    "    #print('layer3: ', x)\n",
    "    \n",
    "    #layer4\n",
    "    x, scale_next, zero_point_next = quantizeBlock(x, model.layer4[0], stats['layer4_0'], \n",
    "                                                   stats['layer4_1']['conv1'], scale_next, zero_point_next)\n",
    "    x, scale_next, zero_point_next = quantizeBlock(x, model.layer4[1], \n",
    "                                                   stats['layer4_1'], stats['fc'], scale_next, zero_point_next)\n",
    "    #print('layer4: ', x)\n",
    "    \n",
    "    #dequantize before the last layer\n",
    "    x = dequantize_tensor(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n",
    "    #print('dequant: ', x)\n",
    "    \n",
    "    #avgpool\n",
    "    x = model.avgpool(x.float())\n",
    "    #print('avgpool: ', x)\n",
    "    \n",
    "    #reshape\n",
    "    x = x.reshape(x.shape[0], -1)\n",
    "    #print('reshape: ', x)\n",
    "    \n",
    "    #fc (fully connected layer)\n",
    "    x = model.fc(x)\n",
    "    #print('fc: ', x)\n",
    "    \n",
    "    #return\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MIN and MAX for Quantizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statsLayer(data, layer):\n",
    "    stats_temp = {}\n",
    "    #conv1\n",
    "    stats_temp['conv1'] = {'max': data.max().detach(), 'min': data.min().detach()}\n",
    "    data1 = layer.conv1(data)\n",
    "    \n",
    "    #bn1\n",
    "    stats_temp['bn1'] = {'max': data1.max().detach(), 'min': data1.min().detach()}\n",
    "    data1 = layer.bn1(data1)\n",
    "    \n",
    "    data1 = layer.relu(data1)\n",
    "    \n",
    "    #conv2\n",
    "    stats_temp['conv2'] = {'max': data1.max().detach(), 'min': data1.min().detach()}\n",
    "    data1 = layer.conv2(data1)\n",
    "    \n",
    "    #bn2\n",
    "    stats_temp['bn2'] = {'max': data1.max().detach(), 'min': data1.min().detach()}\n",
    "    data1 = layer.bn2(data1)\n",
    "    \n",
    "    #downsample\n",
    "    if layer.downsample is not None:\n",
    "        stats_temp_1 = {}\n",
    "        #0\n",
    "        stats_temp_1['0'] = {'max': data.max().detach(), 'min': data.min().detach()}\n",
    "        data = layer.downsample[0](data)\n",
    "        #1\n",
    "        stats_temp_1['1'] = {'max': data.max().detach(), 'min': data.min().detach()}\n",
    "        data = layer.downsample[1](data)\n",
    "        \n",
    "        stats_temp['downsample'] = stats_temp_1\n",
    "        \n",
    "    \n",
    "    data = data1 + data\n",
    "    \n",
    "    data = layer.relu(data)\n",
    "    \n",
    "    return data, stats_temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatherStats(model, data):\n",
    "    stats = {}\n",
    "    \n",
    "    #conv1\n",
    "    stats['conv1'] = {'max': data.max(), 'min': data.min()}\n",
    "    data = model.conv1(data)\n",
    "    \n",
    "    #bn1\n",
    "    stats['bn1'] = {'max': data.max().detach(), 'min': data.min().detach()}\n",
    "    data = model.bn1(data)\n",
    "    \n",
    "    data = model.relu(data)\n",
    "    data = model.maxpool(data)\n",
    "    \n",
    "    #layer1\n",
    "    data, stats['layer1_0'] = statsLayer(data, model.layer1[0])\n",
    "    data, stats['layer1_1'] = statsLayer(data, model.layer1[1])\n",
    "    #layer2\n",
    "    data, stats['layer2_0'] = statsLayer(data, model.layer2[0])\n",
    "    data, stats['layer2_1'] = statsLayer(data, model.layer2[1])\n",
    "    #layer3\n",
    "    data, stats['layer3_0'] = statsLayer(data, model.layer3[0])\n",
    "    data, stats['layer3_1'] = statsLayer(data, model.layer3[1])\n",
    "    #layer3\n",
    "    data, stats['layer4_0'] = statsLayer(data, model.layer4[0])\n",
    "    data, stats['layer4_1'] = statsLayer(data, model.layer4[1])\n",
    "    \n",
    "    #avgpool\n",
    "    data = model.avgpool(data)\n",
    "    \n",
    "    data = data.reshape(data.shape[0], -1)\n",
    "    \n",
    "    #fc\n",
    "    stats['fc'] = {'max': data.max().detach(), 'min': data.min().detach()}\n",
    "    data = model.fc(data)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Quantizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "q_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = gatherStats(q_model, input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = quantForward(q_model, input_batch, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(911)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
